{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name, email and UFID.\n",
    "Please do not modify instruction cells or any cells with automated tests (marked with `[ASSERTS]`). Note: you can add new cells if you need them, but answers must be in the cells with `YOUR CODE HERE` or \"YOUR ANSWER HERE\" comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d95c81ec2e671dc91a774865a6877913",
     "grade": false,
     "grade_id": "homework-preamble",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Homework 1: Basic Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5658c9a4ed21f362746fdaeb7fb21351",
     "grade": false,
     "grade_id": "preamble-name",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Preamble: Write your Name, Email and UFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42779f1b6a28207dc3785b9606317221",
     "grade": false,
     "grade_id": "name-email-ufid",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homework 1 -- name: Hansika Weerasena, email: hansikam.lokukat@ufl.edu, UFID: 11639514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NAME = 'Hansika Weerasena'\n",
    "EMAIL = 'hansikam.lokukat@ufl.edu'\n",
    "UFID = 11639514\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "print('Homework 1 -- name: {}, email: {}, UFID: {}\\n'.format(NAME, EMAIL, UFID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c41a13a5f6e2fa1b47621d28e926c2cf",
     "grade": true,
     "grade_id": "name-email-ufid-asserts",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check that your name, email, and UFID is filled in.\"\"\"\n",
    "assert NAME != '' and NAME != 'Your name here.' and len(NAME) > 3\n",
    "assert EMAIL != '' and EMAIL != 'Your email here.' and len(EMAIL) > 7\n",
    "assert type(UFID) == int and UFID != 12345678 and UFID >= 10000000 and UFID <= 99999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b4f30c4bbc2f9927b1410eeb1f001b3",
     "grade": false,
     "grade_id": "preamble-academic-integrity",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Academic Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99184dabc791053131230787b9f498b8",
     "grade": false,
     "grade_id": "preamble-academic-integrity-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <span style=\"color:red;\">This is an individual assignment. Academic integrity violations (i.e., cheating, plagiarism) will be reported to SCCR!</span><br/>\n",
    "#### The official CISE policy recommended for such offenses is a course grade of E. Additional sanctions may be imposed by SCCR such as marks on your permanent educational transcripts, dismissal or expulsion.\n",
    "#### Reminder of the Honor Pledge: On all work submitted for credit by Students at the University of Florida, the following pledge is either required or implied: *\"On my honor, I have neither given nor received unauthorized aid in doing this assignment.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d8d2452e1d9f6d547eae6447b7ca369",
     "grade": false,
     "grade_id": "cell-preamble-academic-integrity-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Acknowledgement: Do you acknowledge and understand the academic integrity warning above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89bc9ed2e09cb9069b92dc24a3bc081a",
     "grade": false,
     "grade_id": "academic-integrity",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "academic_integrity_acknowledgement = True\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7d6eb103ab3a60e964c163468d9aa7a",
     "grade": true,
     "grade_id": "academic-integrity-assert",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check that you acknowledge the academic integrity warning, you understand it and have been reminded of the UF Honor Pledge.\"\"\"\n",
    "assert academic_integrity_acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07e632f4288ff828557c8092c238d80d",
     "grade": false,
     "grade_id": "task1-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# [Task 1] (25 points) Loading and preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4502f25c9d7137647f8794f306caad2",
     "grade": false,
     "grade_id": "task1-instructb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 1] We will use the diabetes dataset including in sklearn. In this task you will load the data and preprocess it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40e0c6343e3d6ae8ef5568125e9de64f",
     "grade": false,
     "grade_id": "task1-instructc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### The following cell's code (import statements etc.) is provided for you and you should not need to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "119d3a62a34e7425f288493659994237",
     "grade": false,
     "grade_id": "task1-code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "### Python version: 3.9.6 (default, Oct 18 2022, 12:41:40) \n",
      "[Clang 14.0.0 (clang-1400.0.29.202)]\n",
      "### NumPy version: 1.26.3\n",
      "### Scikit-learn version: 1.3.2\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Load packages we need\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Let's check our software versions\n",
    "print('------------')\n",
    "print('### Python version: ' + __import__('sys').version)\n",
    "print('### NumPy version: ' + np.__version__)\n",
    "print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "print('------------')\n",
    "\n",
    "def var_exists(var_name):\n",
    "    return (var_name in globals() or var_name in locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cc6d3b909b447a027649ca1d83883d9",
     "grade": false,
     "grade_id": "seed_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### This is the seed we will use, do not change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90e529cfda4201f99b609dcb560add2a",
     "grade": false,
     "grade_id": "setting_seed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set the seed\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d746a78509c270bb1f51eff6a455a1f6",
     "grade": true,
     "grade_id": "seed_checking",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check seed. \"\"\"\n",
    "assert seed == 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46f667c763a46d6f3f3e29bff945ce94",
     "grade": false,
     "grade_id": "task1a_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 1a] (10 points) Load the 'diabetes' dataset. Extract the feature names into 'feature_names', let 'target_name' be 'target' and create a list of all column names 'col_names' to include both the feature names and the target name. Finally, grab the feature matrix in 'all_x' and target vector in 'all_y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "097c86853dfab4bacb351c6228a404f9",
     "grade": false,
     "grade_id": "task1a_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded diabetes data: 442 rows and 10 features.\n",
      "Column names: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'target'].\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code to load the dataset here.\n",
    "\"\"\"\n",
    "from sklearn import datasets\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "feature_names = diabetes.feature_names\n",
    "target_name = 'target'\n",
    "col_names = feature_names + [target_name]\n",
    "all_x = diabetes.data\n",
    "all_y = diabetes.target\n",
    "\n",
    "# raise NotImplementedError()\n",
    "\n",
    "print('Loaded diabetes data: {} rows and {} features.'.format(all_x.shape[0], all_x.shape[1]))\n",
    "print('Column names: {}.'.format(col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95b15c25fb47b8147fb843ae4b9d9c03",
     "grade": true,
     "grade_id": "task1a_tests",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check dataset was loaded and task 1a completed. \"\"\"\n",
    "\n",
    "assert var_exists('diabetes') and type(diabetes) == sklearn.utils._bunch.Bunch\n",
    "assert var_exists('feature_names') and type(feature_names) == list\n",
    "assert var_exists('target_name')\n",
    "assert var_exists('col_names') and len(col_names) == 11\n",
    "assert var_exists('all_x') and var_exists('all_y')\n",
    "assert all_x.shape == (442,10) and all_y.shape == (442,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a29332e017bc8986248a3a59f80b2f9",
     "grade": false,
     "grade_id": "task1b_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 1b] (5 points) Rescaling features and target. The dataset's features have been mean centered and scaled so the column sum of squares add up to 1. We don't like this so you will rescale each of the features to lie in [0, 1] assuming that each value currently lies in the range [-0.2, 0.2] (clamping any value that falls outside [0,1]). You will store the rescaled feature matrix in 'all_x_rescaled'. \n",
    "## You will then binarize the target vector such that any value less than 140 is labeled 0 and any other value greater is labeled 1 and store the result in 'all_y_threshold'. Finally ensure that the dtype of 'all_y_threshold' is int. (Note: this step creates for us a binary classification task, even though this dataset is more commonly used for regression.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ca65c8f49d9848c5ef993e7d9fc566b",
     "grade": false,
     "grade_id": "task1b_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here to rescale the features and binarize the target.\n",
    "\"\"\"\n",
    "assumed_min_val_x = -0.2\n",
    "assumed_max_val_x = +0.2\n",
    "\n",
    "threshold_y = 140.0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "low = 0\n",
    "high = 1\n",
    "\n",
    "all_x_rescaled = all_x.copy()\n",
    "\n",
    "all_x_rescaled -= assumed_min_val_x\n",
    "all_x_rescaled /= (assumed_max_val_x - assumed_min_val_x)\n",
    "all_x_rescaled = all_x_rescaled * (high - low) + low\n",
    "\n",
    "all_x_rescaled = np.clip(all_x_rescaled, 0, 1)\n",
    "\n",
    "all_y_threshold = np.where(all_y < threshold_y, 0, 1).astype(int)\n",
    "\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f52365d8fd0f2014f92387cfc1575b5c",
     "grade": true,
     "grade_id": "task1b_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check rescaling for task 1b. \"\"\"\n",
    "assert var_exists('all_x_rescaled') and all_x_rescaled.shape == all_x.shape\n",
    "assert var_exists('all_y_threshold') and all_y_threshold.shape == all_y.shape\n",
    "assert all_y_threshold.dtype == int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ce983316138584d07268c5f0e7323ef",
     "grade": false,
     "grade_id": "task1c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 1c] (5 points) Now split the data into (train, val, test) with (0.6, 0.2, 0.2) proportions using 'train_test_split' from sklearn (hint: you will have to invoke the function twice). Make sure you use the seed so that the split is reproducible. Store the results into 'train_x', 'train_y', 'val_x', 'val_y', 'test_x', 'test_y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a31433f341e2506746ddefd71e616b8",
     "grade": false,
     "grade_id": "task1c_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here for the train, val, test split.\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# YOUR CODE HERE\n",
    "train_x, temp_x, train_y, temp_y = train_test_split(all_x_rescaled, all_y_threshold, train_size=0.6, random_state=seed)\n",
    "val_x, test_x, val_y, test_y = train_test_split(temp_x, temp_y, test_size=0.5, random_state=seed)\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d78149e56cddee39557e77bb009b708",
     "grade": true,
     "grade_id": "taskk1c_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check split for task 1c. \"\"\"\n",
    "assert var_exists('train_x') and var_exists('train_y') and train_x.shape[0] == train_y.shape[0]\n",
    "assert var_exists('val_x') and var_exists('val_y') and val_x.shape[0] == val_y.shape[0]\n",
    "assert var_exists('test_x') and var_exists('test_y') and test_x.shape[0] == test_y.shape[0]\n",
    "assert train_x.shape == (265, 10) or train_x.shape == (264, 10)  or train_x.shape == (266, 10) \n",
    "assert val_x.shape == (88, 10) or val_x.shape == (89, 10) or val_x.shape == (87, 10) \n",
    "assert test_x.shape == (88, 10) or test_x.shape == (89, 10) or test_x.shape == (87, 10) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1637c34a4a9e0c68d5d6e7db675c0f3d",
     "grade": false,
     "grade_id": "task1d_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 1d] (5 points) Is the (preprocessed) dataset balanced or not? Justify your answer. Use the training set to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "786fa3bd05b8eaacf673eb566ef99039",
     "grade": true,
     "grade_id": "task1d_answer_manual",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- target ---\n",
      "0: 130\n",
      "1: 135\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here for task 1d. Then answer the question (write your answer in a comment in the space provided).\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "label = col_names[-1]\n",
    "assert len(train_y.shape) <= 1 or train_y.shape[1] == 1\n",
    "if label is not None:\n",
    "    print('--- {} ---'.format(label))\n",
    "for v in np.unique(train_y):\n",
    "    print('{}: {}'.format(v, np.sum(train_y == v)))\n",
    "\n",
    "\n",
    "# raise NotImplementedError()\n",
    "\n",
    "## Answer: The dataset is balanced since the distribution of labels (1,0) is almost uniform. They only differ by 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c78a83bdf81aa58b14f18f8d8852660c",
     "grade": false,
     "grade_id": "task2_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# [Task 2] (25 points) Exploring the data. In this task we will look at the data, specifically correlations in the data and think about potentially redundant or useless features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f27081d88db84cd51832b02cacbd45d",
     "grade": false,
     "grade_id": "task2a_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 2a] (5 points) To look at the data should we use the training set, the validation set, the test set or all of the data? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71cdd4763dce9a43230dbfbd8f759882",
     "grade": true,
     "grade_id": "task2a_answer_manual",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7833f650bed447f9010c94ad7776fcc",
     "grade": false,
     "grade_id": "task2b_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 2b] (10 points) Create a visualization of the training data correlations. You can do a heatmap like we did in exercise 1, you can use pandas and plot a scatter matrix, or you can do it manually. But your code must be self-contained and fit in the cell below and it must show/quantify the correlations between any pairs of features or any feature and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8d70ac24148c2a3b15b75bc506b1c9f",
     "grade": false,
     "grade_id": "task2b_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here for task 2b. The code must be self-contained to this cell.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f17e6fa336528763992996be72193aa",
     "grade": true,
     "grade_id": "task2b_answer_manual",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" THIS CODE CELL IS INTENTIONALLY LEFT EMPTY.  Remove the 'raise NotImplementedError' line. You should leave this cell empty (it is used for autograding). (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# THIS CODE CELL IS INTENTIONALLY LEFT EMPTY --- DO NOT MODIFY THIS CELL\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "241c175eb0efc4a9fc2f4c765165665f",
     "grade": false,
     "grade_id": "task2c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 2c] (5 points) According to your visualization: what are the four features that are the most informative with respect to the target? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5711dc12338b7078d6e93de0287a9c10",
     "grade": false,
     "grade_id": "task2c_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put any code on this cell that may help you answer task2c or 2d.\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "541f5a922082134ea66743cda59d2e57",
     "grade": true,
     "grade_id": "task2c_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e726c2bf7e79f15385bc27aa7dd8806",
     "grade": false,
     "grade_id": "task2d_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 2d] (5 points) Are there any features that are redundant and that you would consider removing. If so, which ones and why and if not why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98669ceb908ea3f5102b6877c6b5a8db",
     "grade": true,
     "grade_id": "task2d_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9928e21cb168ffcd9b1a07881c1460db",
     "grade": false,
     "grade_id": "task3_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# [Task 3] (25 points) Learning curves and data augmentation. In this task you will train SVM models, plot learnings curves, and try some (simple) data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cccc177fc6292b4341461326c53de459",
     "grade": false,
     "grade_id": "task3a_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 3a] (5 points) Fill in the blanks to complete the code of the following two methods which we will use to train and evaluate the accuracy of models in the rest of the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9812015f79810258389a719541d36fc5",
     "grade": false,
     "grade_id": "task3a_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\"\"\"Fill in the code for 'model_acc' so the function returns the accuracy of the predictions on 'x'. Use 'accuracy_score' from sklearn. ('y' contains the true labels.)\n",
    "\"\"\"\n",
    "def model_acc(model, x, y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\"\"\"Fill in the code for 'train_and_eval_acc' so the function computes and return the train accuracy ('tr_acc') and the eval accuracy ('eval_acc'). Your code should use 'model_acc'.\n",
    "\"\"\"\n",
    "def train_and_eval_acc(model_instance, tr_x, tr_y, eval_x, eval_y):\n",
    "    model = model_instance.fit(tr_x, tr_y) # trains the model\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return tr_acc, eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b01703488e58aeab90fceb2485a4687",
     "grade": true,
     "grade_id": "task3a_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 3a. \"\"\"\n",
    "\n",
    "train_acc, val_acc = train_and_eval_acc(SVC(random_state=seed), train_x, train_y, val_x, val_y)\n",
    "\n",
    "assert np.abs(train_acc - 0.8) < 0.1\n",
    "assert np.abs(val_acc - 0.8) < 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a5b1ba4ee0520d3809e79dbeedd77f3",
     "grade": false,
     "grade_id": "task3_no_modify1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The following is provided code to help you plot learning curves. You should not need to modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d33f6ea8551aa29bf7d0fc3200148701",
     "grade": false,
     "grade_id": "task3_no_modify2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(train_szs, accs, model_name):\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "    assert accs.shape[-1] == 2, 'Must have last dim of size 2 with train acc and val/test acc.'\n",
    "    assert len(accs.shape) == 2 or len(accs.shape) == 3, 'Invalid input'\n",
    "\n",
    "    multiple_measurements = len(accs.shape) == 3\n",
    "    if multiple_measurements:\n",
    "        std_accs = np.std(accs, axis=0)\n",
    "        accs = np.mean(accs, axis=0)\n",
    "    \n",
    "    plt.plot(train_szs, accs[:,0]*100.0, 'ro-', linewidth=3, label='Training')\n",
    "    plt.plot(train_szs, accs[:,1]*100.0, 'bs--', linewidth=3, label='Test/Validation')\n",
    "\n",
    "    if multiple_measurements:\n",
    "        laccs = accs - std_accs\n",
    "        uaccs = accs + std_accs\n",
    "        plt.fill_between(train_szs, laccs[:,0]*100.0, uaccs[:,0]*100.0, color='r', alpha=0.3)\n",
    "        plt.fill_between(train_szs, laccs[:,1]*100.0, uaccs[:,1]*100.0, color='b', alpha=0.3)\n",
    "\n",
    "    ax.set_xlim(0, np.max(train_szs))\n",
    "    ax.set_ylim(54, 104)\n",
    "    ax.set_xlabel('Number of training examples')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Learning Curves for {}'.format(model_name))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16c19cf363b899c90ef460c00579b0ea",
     "grade": false,
     "grade_id": "task3b_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 3b] (5 points) Fill in the code below to plot the learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f614c0d8c7802a914fbd6a07de56f1eb",
     "grade": false,
     "grade_id": "task3b_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Fill in the code for 'get_learning_curve_acc' so the function trains and evaluate a SVC model (default parameters but set the seed) on 'tr_x/y' \n",
    "and 'eval_x_/y_' using 'train_and_eval_acc' in each iteration of the loop.\n",
    "\"\"\"\n",
    "def get_learning_curve_acc(tr_sizes, train_x_, train_y_, eval_x_, eval_y_):\n",
    "    pi = np.random.permutation(train_x.shape[0])\n",
    "    shuf_tr_x = train_x_[pi]\n",
    "    shuf_tr_y = train_y_[pi]\n",
    "    lc_arr = np.zeros((tr_sizes.shape[0],2))\n",
    "    \n",
    "    for i, tr_sz in enumerate(tr_sizes):\n",
    "        tr_x = shuf_tr_x[0:tr_sz]\n",
    "        tr_y = shuf_tr_y[0:tr_sz]\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        lc_arr[i,:] = [tr_acc, val_acc]\n",
    "        \n",
    "    return lc_arr\n",
    "\n",
    "\n",
    "# the following will compute and plot the learning curves.\n",
    "tr_sizes = np.array([15, 20, 25, 50, 100, 150, 200, 250,])\n",
    "num_samples = 100\n",
    "lc_arrs = None\n",
    "\n",
    "for i in range(0, num_samples):\n",
    "    lc_arr = get_learning_curve_acc(tr_sizes, train_x, train_y, val_x, val_y)\n",
    "    lc_arrs = lc_arr[np.newaxis,:] if lc_arrs is None else np.r_[lc_arrs, lc_arr[np.newaxis,:]]\n",
    "\n",
    "plot_learning_curves(tr_sizes, lc_arrs, 'SVM on Diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba43c37e9da9829353389dc9a4320f86",
     "grade": true,
     "grade_id": "task3b_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 3b. \"\"\"\n",
    "\n",
    "assert var_exists('lc_arrs') and lc_arrs.shape == (100, tr_sizes.shape[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3a5d384c3e74c5ef85c8ac52d4ad272",
     "grade": true,
     "grade_id": "task3b_manual",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" THIS CODE CELL IS INTENTIONALLY LEFT EMPTY.  Remove the 'raise NotImplementedError' line. You should leave this cell empty (it is used for autograding). (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# THIS CODE CELL IS INTENTIONALLY LEFT EMPTY --- DO NOT MODIFY THIS CELL\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4282154b3a0c18c24e620047e90f58ca",
     "grade": false,
     "grade_id": "task3c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 3c] (5 points) What can we say about the amount of training data from the learning curve? Would more data improve the model? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d66881b417c5dd2ae2db04fd3ff34dda",
     "grade": true,
     "grade_id": "task3c_answer_manual",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17d48203d4bc456e3f8ab2f6885eca5f",
     "grade": false,
     "grade_id": "task3d_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 3d] (5 points) It's time to try some data augmentation. Fill in the body of the loop. The provided code will add Gaussian noise (mean 0, standard dev sigma) to the training features to augment the dataset. It will then train and evaluate SVM models on the original data and the augmented data for various sigmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91815405c550e01830db2ac5c10b81f0",
     "grade": false,
     "grade_id": "task3d_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Add gaussian noise with mean 0 and standard deviation sigma to feature matrix x. Returns x and noisy x. \"\"\"\n",
    "def add_gaussian_noise(x, y, sigma):\n",
    "    noisy_x = x + np.random.randn(*x.shape)*sigma\n",
    "    out_x = np.r_[x, noisy_x]\n",
    "    out_x = np.clip(out_x, 0.0, 1.0)\n",
    "    out_y = np.r_[y, y]\n",
    "    pi = np.random.permutation(out_x.shape[0])\n",
    "    return out_x[pi,:], out_y[pi]\n",
    "\n",
    "\n",
    "# first evaluate the model on the original data\n",
    "train_acc_orig, val_acc_orig = train_and_eval_acc(SVC(random_state=seed), train_x, train_y, val_x, val_y)\n",
    "print('[Original] Model accuracy --- train: {:.1f}%, val: {:.1f}%\\n'.format( 100*train_acc_orig, 100*val_acc_orig))\n",
    "\n",
    "\n",
    "num_runs = 100\n",
    "sigmas = [0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 1.0, 5.0, 10.0]\n",
    "for sigma in sigmas:\n",
    "    aug_accs = np.zeros((num_runs,2))\n",
    "    for i in range(0, num_runs):\n",
    "        \"\"\" Fill in the body of the loop to use add_gaussian_noise to augment the training data and then train and evaluate an SVC model (default parameters but set the seed). \n",
    "        Store the training accuracy in 'train_acc_aug' and the validation accuracy in 'val_acc_aug' \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        aug_accs[i,:] = [train_acc_aug, val_acc_aug]\n",
    "\n",
    "    mean_train_acc = np.mean(aug_accs[:, 0])\n",
    "    mean_val_acc = np.mean(aug_accs[:, 1])\n",
    "\n",
    "    print('[Augmented sigma={:.2f}] --- train: {:.1f}%, val: {:.1f}%'.format(sigma, 100*mean_train_acc, 100*mean_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91aa0f5745cced761493dfe06123050f",
     "grade": true,
     "grade_id": "task3d_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 3d. \"\"\"\n",
    "\n",
    "assert var_exists('aug_accs') and np.amin(aug_accs) > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d8be8e2fa26a6cd18958867f9a45cf8",
     "grade": false,
     "grade_id": "task3e_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 3e] (5 points) Answer the following questions. (Q1) Is data augmentation effective in this case? Why or why not? (Q2) What do you observe to the train accuracy as sigma increases? Explain why this occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fe300e79c25ad3070143141c7071e4c",
     "grade": true,
     "grade_id": "task3e_answer_manual",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer to (Q1):\n",
    "#\n",
    "## Answer to (Q2):\n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c79ba51c3686aecd7a733b6fa871ec0c",
     "grade": false,
     "grade_id": "task4_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# [Task 4] (25 points) Naive Bayes. In this task you will train Naive Bayes models and for that you will do some feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9470deea505023ef277e367bd700416",
     "grade": false,
     "grade_id": "task4a_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 4a] (5 points) Read up on Naive Bayes and answer the following questions in your own words. (Q1) What is the main assumption built into Naive Bayes models? Is this assumption reasonable? Why or why not? (Q2) The sklearn documentation on Naive Bayes (https://scikit-learn.org/stable/modules/naive_bayes.html) states \"naive Bayes is known as a decent classifier, it is known to be a bad estimator.\" What does that mean and why is that? Two or three sentences is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "732cef3ea8405f78eeac455121add474",
     "grade": true,
     "grade_id": "task4a_answer_manual",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer to (Q1):\n",
    "#\n",
    "## Answer to (Q2):\n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "845ba2d2ceacc36de6f1d9a4074e5eed",
     "grade": false,
     "grade_id": "task4b_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 4b] (5 points) Fill in the code below to train a GaussianNB classifier (default parameters) on the training set and evaluate it on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52ecd83653f3989f2185ee0fafafa35c",
     "grade": false,
     "grade_id": "task4b_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB\n",
    "\n",
    "\"\"\" Fill in the code to train GaussianNB on the training data and evaluate the accuracy on the validation data (use default parameters). \n",
    "Store the training accuracy in 'train_acc' and the validation accuracy in 'val_acc' (use 'train_and_eval_acc'). \"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print('[GaussianNB] Train acc: {:.1f}%, Val acc: {:.1f}%'.format(100*train_acc, 100*val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fd5b1f26bca519e03f0d851a4dcf7c7",
     "grade": true,
     "grade_id": "task4b_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4b. \"\"\"\n",
    "\n",
    "assert var_exists('train_acc') and var_exists('val_acc')\n",
    "assert train_acc > 0.7 and val_acc > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87b5adc12633789aea8377dd550e0735",
     "grade": false,
     "grade_id": "task4c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 4c] (10 points) Implement real_to_categ() function to transform real features to categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4d90eb3a6affb1d92f11f793bd2f3ec",
     "grade": false,
     "grade_id": "task4c_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Fill in the code for real_to_categ. The function takes a n-by-m feature matrix 'x' of reals with m features and n examples. \n",
    "It return a n-by-m matrix of categorical features 'cat_x' where feature i,j of cat_x is has value integer k if  feature i,j of 'x' falls within the kth bin\n",
    "according 'bins'. If 'bins' is None then the function first creates 'num_bins' equally-space bins for each feature between the min and max values for that feature.\n",
    "In addition to 'cat_x' the function returns 'bins' (the created or given bins) which is a m-by-num_bins array of bin edges.\n",
    "\n",
    "Note: You can implement this however you like, but I recommend staying away from sklearn.preprocessing classes such as OrdinalEncoder as it may not do what you think.\n",
    "(Hint: you can use numpy.linspace() to create bins and numpy.digitize to determine placement of real feature values in bins.)\n",
    "\"\"\"\n",
    "def real_to_categ(x, bins=None, num_bins=5):\n",
    "    assert num_bins > 1\n",
    "    if bins is not None:\n",
    "        assert type(bins) == np.ndarray\n",
    "        assert bins.shape == (x.shape[1],num_bins), 'Invalid bins.'\n",
    "        \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    cat_x = np.clip(cat_x, 1, num_bins) # clip so no features falls outside of the bins.\n",
    "    return cat_x.astype(int), bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0158700c46a1eab843c81b5bc5f2a908",
     "grade": true,
     "grade_id": "task4c_tests",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4c. \"\"\"\n",
    "\n",
    "x = np.c_[(np.arange(1, 10)/10.0), np.flipud(np.arange(0, 9)/10.0)]\n",
    "\n",
    "cat_x, bins_x = real_to_categ(x)\n",
    "assert cat_x is not None and bins_x is not None\n",
    "assert x.shape == cat_x.shape\n",
    "assert np.amin(cat_x) == 1 and np.amax(cat_x) == 5\n",
    "\n",
    "correct_bins = np.array([[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "                          [0.0, 0.2, 0.4, 0.6, 0.8]])\n",
    "assert bins_x.shape == correct_bins.shape and np.sum(np.abs(bins_x - correct_bins)) < 1e-8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d6ac3ce2f5707820a22ec0e591a18e5",
     "grade": false,
     "grade_id": "task4d_preinstruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 4] The following code will transform the data to categorical use 'real_to_categ' and train and evaluate a CategoricalNB model on it. You do not need to modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "367173701ce29cc5958ad40874abdc4c",
     "grade": false,
     "grade_id": "task4d_preinstruct2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train and evaluate CategoricalNB on the real features.\n",
    "train_acc, val_acc = train_and_eval_acc(CategoricalNB(), train_x, train_y, val_x, val_y)\n",
    "print('[CategoricalNB w/ real features] Train acc: {:.1f}%, Val acc: {:.1f}%'.format(100*train_acc, 100*val_acc))\n",
    "\n",
    "# transform the features to categorical data using bins learned from train_x.\n",
    "cat_train_x, bins = real_to_categ(train_x, bins=None)\n",
    "cat_val_x, _ = real_to_categ(val_x, bins=bins)\n",
    "cat_test_x, _ = real_to_categ(test_x, bins=bins)\n",
    "\n",
    "# train and evaluate CategoricalNB on the categorical features.\n",
    "train_acc, val_acc = train_and_eval_acc(CategoricalNB(), cat_train_x, train_y, cat_val_x, val_y)\n",
    "print('[CategoricalNB w/ categorical features] Train acc: {:.1f}%, Val acc: {:.1f}%'.format(100*train_acc, 100*val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0314cd3227bae939f890e93f5baf56b3",
     "grade": false,
     "grade_id": "task4d_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 4d] (5 points) Use the real_to_categ() function to binarize real features so you can then train and evaluate a BernoulliNB model on the binarized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e56244b182509bb72bf5b535a71ad9b1",
     "grade": false,
     "grade_id": "task4d_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Fill in the code to binarize the feature matrix so that features x with values below the 67th percentile are mapped to 0 and values above are mapped to 1.\n",
    "For this you should use 'real_to_categ' with appropriately chosen bins derived from 'train_x' percentiles.\n",
    "Put the resulting arrays in 'bin_train_x', 'bin_val_x', and 'bin_test_x'. \n",
    "Note that the bins must be derived from 'train_x' and then applied to val and test.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "# train and evaluate BernoulliNB on the real features.\n",
    "train_acc, val_acc = train_and_eval_acc(BernoulliNB(), train_x, train_y, val_x, val_y)\n",
    "print('[BernoulliNB w/ real features] Train acc: {:.1f}%, Val acc: {:.1f}%'.format(100*train_acc, 100*val_acc))\n",
    "\n",
    "# train and evaluate BernoulliNB on the binary features.\n",
    "train_acc, val_acc = train_and_eval_acc(BernoulliNB(), bin_train_x, train_y, bin_val_x, val_y)\n",
    "print('[BernoulliNB w/ binary features] Train acc: {:.1f}%, Val acc: {:.1f}%'.format(100*train_acc, 100*val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be112b1ae75358fae059791fd38b93a9",
     "grade": true,
     "grade_id": "task4d_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4d. \"\"\"\n",
    "\n",
    "assert var_exists('bin_train_x') and var_exists('bin_val_x') and var_exists('bin_test_x')\n",
    "assert np.amin(bin_train_x) == 0 and np.amax(bin_train_x) == 1 and np.array_equal(bin_train_x, bin_train_x.astype(int))\n",
    "assert train_x.shape == bin_train_x.shape\n",
    "assert np.amin(bin_val_x) == 0 and np.amax(bin_val_x) == 1 and np.array_equal(bin_val_x, bin_val_x.astype(int))\n",
    "assert bin_val_x.shape == bin_val_x.shape\n",
    "assert np.amin(bin_test_x) == 0 and np.amax(bin_test_x) == 1 and np.array_equal(bin_test_x, bin_test_x.astype(int))\n",
    "assert bin_test_x.shape == bin_test_x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99f4a8688d6bf2f9df7755eb1f7d609b",
     "grade": false,
     "grade_id": "task5_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# [Task 5] \\<*For CAI6108MLE Only*\\> (25 points) Hyperparameter search. For this task you will choose two hyperparameters to optimize and you will fill in the code below to optimize them using grid search and train a model with the best hyperparameter values. Other than the two hyperparameter you choose you should only modify the seed and/or the maximum number of iterations (if applicable).\n",
    "# The type of model you have to use depends on the *last* digit of your UFID:\n",
    "## + SVC if the last digit is 2, 3, 5, or 7;\n",
    "## + KNeighborsClassifier if the last digit is 1, 4, or 6; and\n",
    "## + GaussianNB otherwise (if the last digit is 0, 8 or 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4717206171f8e588509fd941e459a642",
     "grade": false,
     "grade_id": "task5_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\"\"\"Fill in the code for the hyperparameter search. You must choose only two hyperparameters to tune, leave the default value for the rest (except seed/max_iter if applicable).\n",
    "Your code must return 'best_hyperparams' the best combination of hyperparameters you found and 'best_model' the corresponding trained model.\n",
    "Your code must run in only a few seconds to enable automatic grading (e.g., less than 30 seconds).\n",
    "\"\"\"\n",
    "def search_hyperparams_and_train(train_x, train_y, val_x, val_y):\n",
    "    best_hyperparams = {}\n",
    "    best_model = None\n",
    "\n",
    "    print('Searching for hyperparameters (UFID: {})'.format(UFID))\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return best_model, best_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd942c244f7f2be4af4a066562ac85f4",
     "grade": false,
     "grade_id": "task5_misc1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 5] The following code is provided, you should not modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "974ceae975c9d577e198b6209a714846",
     "grade": false,
     "grade_id": "task5_misc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "model, hyperparams = search_hyperparams_and_train(train_x, train_y, val_x, val_y)\n",
    "et = time.time()\n",
    "\n",
    "elapsed = et - st\n",
    "print('Elapsed time: {:.1f} seconds [model type: {}, hyperparams: {}]'.format(elapsed, model.__class__.__name__, hyperparams))\n",
    "\n",
    "train_acc = model_acc(model, train_x, train_y)\n",
    "val_acc = model_acc(model, val_x, val_y)\n",
    "test_acc = model_acc(model, test_x, test_y)\n",
    "\n",
    "print('Train acc: {:.1f}%, val acc: {:.1f}%, test acc: {:.1f}%'.format(100*train_acc, 100*val_acc, 100*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a749b5e5d991f0708f3c065fc0f1458",
     "grade": true,
     "grade_id": "task5_tests",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 5. \"\"\"\n",
    "\n",
    "assert var_exists('model')\n",
    "assert elapsed < 30.0 # less than 30 seconds.\n",
    "assert np.amin([train_acc, val_acc, test_acc]) > 0.6\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
