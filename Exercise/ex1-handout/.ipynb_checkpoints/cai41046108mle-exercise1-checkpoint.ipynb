{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Wine Classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages we need\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import scipy.stats as stats\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Let's check our software versions\n",
    "print('### Python version: ' + sys.version)\n",
    "print('### Numpy version: ' + np.__version__)\n",
    "print('### Scipy version: ' + sp.__version__)\n",
    "print('### Pandas version: ' + pd.__version__)\n",
    "print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "print('------------')\n",
    "\n",
    "\n",
    "# load our packages / code\n",
    "sys.path.insert(1, '../common/')\n",
    "import utils\n",
    "import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters to control behavior of the pre-processing, ML, analysis, etc.\n",
    "seed = 42\n",
    "\n",
    "np.random.seed(seed) # deterministic seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting stuff starts now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to load the data from compressed CSV\n",
    "#wine_type = 'red'\n",
    "wine_type = 'white'\n",
    "\n",
    "df = pd.read_csv('../data/{}-wine-quality.csv'.format(wine_type), header=0, na_values='?', sep=' *; *', skipinitialspace=True, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we loaded the data as expected\n",
    "if wine_type == 'white':\n",
    "    df_expected_shape = (4898,12)\n",
    "else:\n",
    "    df_expected_shape = (1599,12)\n",
    "    \n",
    "assert df.shape == df_expected_shape, 'Unexpected shape of df!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick tip: use info() to get a glance at the size and attributes of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a few rows of our dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many records do we have?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## header right now: fixed acidity;volatile acidity;citric acid;residual sugar;chlorides;free sulfur dioxide;total sulfur dioxide;density;pH;sulphates;alcohol;quality\n",
    "col_names = df.columns\n",
    "col_names = [x for x in col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all columns are numerical and the last one 'quality' is what we want to predict\n",
    "#### Note: quality is a score between 0 (very bad) and 10 (excellent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all the data as a numpy array\n",
    "all_xy = np.asarray(df, dtype='float64')\n",
    "# a different way of accomplishing the same thing is: all_xy = df.to_numpy(dtype='float64')\n",
    "assert all_xy.shape[1] == 12\n",
    "\n",
    "# grab label and features column indices\n",
    "label_col_idx = all_xy.shape[1]-1\n",
    "features_col_idx = range(0, label_col_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's separate features from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features from the label\n",
    "all_x = all_xy[:,features_col_idx]\n",
    "all_y = all_xy[:,label_col_idx]\n",
    "all_y = all_y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split between train, test, and validation\n",
    "prop_vec = [14, 3, 3]\n",
    "train_x, train_y, test_x, test_y, val_x, val_y = utils.train_test_val_split(all_x, all_y, prop_vec, shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check shapes\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape, val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats & Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the distribution of labels look like?\n",
    "label_name = col_names[label_col_idx]\n",
    "utils.print_array_hist(train_y, label=label_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearly, this is not a balanced dataset (we will see later on why this can matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot a histogram to visualize the distribution of labels\n",
    "bins = np.arange(-1, 11) + 0.5\n",
    "\n",
    "plt.hist(train_y, bins, density=False, alpha=0.5, edgecolor='k', label=label_name)\n",
    "\n",
    "plt.xticks(np.arange(11))\n",
    "plt.xlabel(label_name)\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: what do you think is a good baseline for predicting the quality exactly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the distribution of features look like?\n",
    "for i in range(train_x.shape[1]):\n",
    "    utils.print_array_basic_stats(train_x[:, i], label=col_names[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Do the features even help us predict the quality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature distribution based on quality\n",
    "\n",
    "#feature_idx = 0; bins = np.linspace(3, 12, 12)\n",
    "#feature_idx = 3; bins = np.linspace(0, 70, 20)\n",
    "feature_idx = 10; bins = np.linspace(7, 15, 12)\n",
    "\n",
    "lowq_idx = train_y == 4 # low quality wines\n",
    "highq_idx = train_y == 8 # high quality wines\n",
    "\n",
    "plt.hist(train_x[lowq_idx,feature_idx], bins, density=True, alpha=0.5, edgecolor='k', label='Low quality')\n",
    "plt.hist(train_x[highq_idx,feature_idx], bins, density=True, alpha=0.5, edgecolor='k', label='High quality')\n",
    "\n",
    "plt.xlabel('{}'.format(col_names[feature_idx]))\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we look at the statistical information that features contain about the task in a systematic way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: this may be in your assignment!\n",
    "\n",
    "train_xy = np.hstack((train_x, train_y.reshape(-1, 1)))\n",
    "\n",
    "pairwise_corr = np.corrcoef(train_xy, rowvar=False)\n",
    "\n",
    "plots.heatmap(pairwise_corr, col_names, col_names, rot=90, fsz=(14, 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Left as exercise]: use Pandas' scatter_matrix to look at scatter plots for the correlation. *Good exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ref: https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should we scale features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(copy=True)\n",
    "scaler.fit(train_x) # fit on the training set! Why?\n",
    "\n",
    "train_x_scaled = scaler.transform(train_x)\n",
    "test_x_scaled = scaler.transform(test_x)\n",
    "val_x_scaled = scaler.transform(val_x)\n",
    "\n",
    "#note:  we don't scale y. Q: why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "import time\n",
    "\n",
    "# Step 1: instantiate the model and set hyperparameters\n",
    "## refer to: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "svm = SVC(kernel='linear', random_state=seed)\n",
    "svm_scaled = clone(svm)\n",
    "\n",
    "# Step 2: train the model (we use the training set)\n",
    "st = time.time()\n",
    "svm.fit(train_x, train_y)\n",
    "et1 = time.time()\n",
    "_ = svm_scaled.fit(train_x_scaled, train_y)\n",
    "et2 = time.time()\n",
    "\n",
    "print('[Training Time] unscaled: {:.1f} seconds, scaled: {:.1f} seconds'.format(et1 - st, et2 - et1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: instantiate the model and set hyperparameters\n",
    "## refer to: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_scaled = clone(knn)\n",
    "\n",
    "# Step 2: train the model (we use the training set)\n",
    "st = time.time()\n",
    "knn.fit(train_x, train_y)\n",
    "et1 = time.time()\n",
    "_ = knn_scaled.fit(train_x_scaled, train_y)\n",
    "et2 = time.time()\n",
    "\n",
    "print('[Training Time] unscaled: {:.2f} seconds, scaled: {:.2f} seconds'.format(et1 - st, et2 - et1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's evaluate our models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "# define a function to calculate accuracy\n",
    "def model_accuracy(model, x, true_y):\n",
    "    pred = model.predict(x)\n",
    "    return np.sum(pred == true_y) / true_y.shape[0]\n",
    "\n",
    "def evaluate_model(name, model, train_x, train_y, val_x, val_y):\n",
    "    train_acc = model_accuracy(model, train_x, train_y)\n",
    "    val_acc = model_accuracy(model, val_x, val_y)\n",
    "    print('[{}] Training accuracy: {:.2f}%, Validation accuracy: {:.2f}%'.format(name, train_acc*100, val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model('SVM', svm, train_x, train_y, val_x, val_y)\n",
    "evaluate_model('SVM (w/ scaled features)', svm_scaled, train_x_scaled, train_y, val_x_scaled, val_y)\n",
    "evaluate_model('KNN', knn, train_x, train_y, val_x, val_y)\n",
    "evaluate_model('KNN (w/ scaled features)', knn_scaled, train_x_scaled, train_y, val_x_scaled, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Does scaling features make a difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Wait. What's going on with 100% accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Is around 50% a good model? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the label distribution look like?\n",
    "utils.print_array_hist(train_y, label='Label distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Baselines?\n",
    "# baseline: random between 1 and 10\n",
    "# --> baseline accuracy: ~10%\n",
    "\n",
    "# better baseline: predict the mode\n",
    "mode = stats.mode(train_y)[0]\n",
    "print('Mode: {}'.format(mode)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pred_y_train = (np.ones_like(train_y) * mode).astype(int)\n",
    "baseline_pred_y_val = (np.ones_like(val_y) * mode).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How good is the baseline?\n",
    "def pred_accuracy(true_y, pred_y):\n",
    "    return np.sum(pred_y == true_y) / true_y.shape[0]\n",
    "\n",
    "def evaluate_baseline(name, train_y, pred_y_train, val_y, pred_y_val):\n",
    "    train_acc = pred_accuracy(train_y, pred_y_train)\n",
    "    val_acc = pred_accuracy(val_y, pred_y_val)\n",
    "    print('[{}] Training accuracy: {:.2f}%, Validation accuracy: {:.2f}%'.format(name, train_acc*100, val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_baseline('Baseline (mode)', train_y, baseline_pred_y_train, val_y, baseline_pred_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different way to do the same thing with sklearn\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html\n",
    "from sklearn.dummy import DummyClassifier \n",
    "\n",
    "mode_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "mode_clf.fit(train_x, train_y)\n",
    "\n",
    "baseline_pred_y_train = mode_clf.predict(train_x)\n",
    "baseline_pred_y_val = mode_clf.predict(val_x)\n",
    "\n",
    "evaluate_baseline('Baseline (mode - sklearn dummy classifier)', train_y, baseline_pred_y_train, val_y, baseline_pred_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
