{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9: Convolutional Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages we need\n",
    "import sys\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# we'll use keras for neural networks\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# import layers we will use\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Concatenate, Dropout\n",
    "\n",
    "# import callbacks we will use\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Let's check our software versions\n",
    "print('### Python version: ' + sys.version)\n",
    "print('### Numpy version: ' + np.__version__)\n",
    "print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "print('### Tensorflow version: ' + tf.__version__)\n",
    "print('------------')\n",
    "\n",
    "\n",
    "# load our packages / code\n",
    "sys.path.insert(1, '../common/')\n",
    "import utils\n",
    "import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters to control behavior of the pre-processing, ML, analysis, etc.\n",
    "\n",
    "seed = 42 # deterministic seed\n",
    "np.random.seed(seed) \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "prop_vec = [24, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_fashion_mnist(minmax_normalize=True):\n",
    "    \n",
    "    labels = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    train, testval = fashion_mnist.load_data()\n",
    "    \n",
    "    train_x, train_y = train\n",
    "    testval_x, testval_y = testval\n",
    "    \n",
    "    if minmax_normalize:\n",
    "        train_x = train_x / 255.0\n",
    "        testval_x = testval_x / 255.0\n",
    "    \n",
    "    # split test - val\n",
    "    nval = testval_x.shape[0] // 2\n",
    "    \n",
    "    val_x = testval_x[:nval]\n",
    "    val_y = testval_y[:nval]\n",
    "    \n",
    "    test_x = testval_x[nval:]\n",
    "    test_y = testval_y[nval:]\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y, val_x, val_y, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, val_x, val_y, labels = load_preprocess_fashion_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 25\n",
    "label_idx = train_y[:num_images].astype(int)\n",
    "titles = labels[label_idx]\n",
    "plots.plot_images(train_x[:num_images].reshape(-1, 28, 28), dim_x=28, dim_y=28, fig_size=(9,9), titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_functional(input_shape=(28, 28)):  \n",
    "    \n",
    "    # let's use the functional API to create a model\n",
    "    input_layer = Input(shape=input_shape, name='Input')\n",
    "    \n",
    "    flatten_layer = Flatten(name='Flatten')(input_layer)\n",
    "    fc1 = Dense(300, name='FC1', activation='relu')(flatten_layer)\n",
    "    fc2 = Dense(100, name='FC2', activation='relu')(fc1)\n",
    "    output_layer = Dense(10, name='Output', activation='softmax')(fc2)\n",
    "    \n",
    "    model = keras.Model(name='FC-model', inputs=[input_layer], outputs=[output_layer])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model_functional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the model look like?\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up an early stopping callback\n",
    "early_stop_cb = EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "# set up a model checkpointing callback\n",
    "fp = \"./mymodel-bestweights.tf\"\n",
    "checkpoint_cb = ModelCheckpoint(fp, monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "max_epochs = 100\n",
    "batch_size = 64\n",
    "history = model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=max_epochs, batch_size=batch_size, \n",
    "                     shuffle=True, callbacks=[early_stop_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we train a CNN for Fashion MNIST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compile_cnn(input_shape=[28, 28, 1], num_outputs=10, verbose=False):\n",
    "    \n",
    "    name = 'CNN'    \n",
    "    model = keras.models.Sequential(name=name)\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(7,7), input_shape=input_shape,\n",
    "                     padding='same', activation='relu', name='conv1'))\n",
    "    model.add(MaxPooling2D(2, name='maxpool1')) \n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same', name='conv2'))\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same', name='conv3'))\n",
    "    model.add(MaxPooling2D(2, name='maxpool2'))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', name='conv4'))\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same', name='conv5'))\n",
    "    model.add(MaxPooling2D(2, name='maxpool3'))\n",
    "    \n",
    "    model.add(Flatten(name='flatten'))\n",
    "    \n",
    "    model.add(Dense(128, activation='relu', name='fc1'))\n",
    "    model.add(Dropout(0.5, name='dropout1'))\n",
    "    model.add(Dense(64, activation='relu', name='fc2'))\n",
    "    model.add(Dropout(0.5, name='dropout2'))\n",
    "    \n",
    "    model.add(Dense(num_outputs, activation=\"softmax\", name='output'))\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.002)\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return name, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, model = create_compile_cnn(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_cnn_fp = 'fashion-MNIST-CNN.tf'\n",
    "load = os.path.exists(fashion_mnist_cnn_fp)\n",
    "\n",
    "if load:\n",
    "    fashion_mnist_cnn_model = tf.keras.models.load_model(fashion_mnist_cnn_fp)\n",
    "else:\n",
    "    name, model = create_compile_cnn(verbose=True)\n",
    "\n",
    "    early_stop_cb = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    max_epochs = 15\n",
    "    batch_size = 64\n",
    "\n",
    "    if len(train_x.shape) < 4:\n",
    "        train_x = train_x.reshape(-1, 28, 28, 1)\n",
    "        val_x = val_x.reshape(-1, 28, 28, 1)\n",
    "        test_x = test_x.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    history = model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=max_epochs, batch_size=batch_size, \n",
    "                         shuffle=True, callbacks=[early_stop_cb])\n",
    "\n",
    "    # save the model\n",
    "    model.save(fashion_mnist_cnn_fp)\n",
    "    fashion_mnist_cnn_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we reuse this model for a different task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try to use the fashion MNIST model for MNIST digit classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the MNIST data\n",
    "train_x, train_y, test_x, test_y, val_x, val_y, all_x, all_y = utils.load_preprocess_mnist_data(onehot=False, flatten=False, prop_vec=prop_vec, seed=seed)\n",
    "\n",
    "# min-max normalize\n",
    "train_x = train_x / 255.0\n",
    "test_x = test_x / 255.0\n",
    "val_x = val_x / 255.0\n",
    "    \n",
    "# reshape the data because tensorflow excepts 4d tensors\n",
    "train_x = train_x.reshape(-1, 28, 28, 1)\n",
    "test_x = test_x.reshape(-1, 28, 28, 1)\n",
    "val_x = val_x.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's clone the pretrained model and duplicate the weights\n",
    "# cloning ensure we won't modify the original model's weights accidentally\n",
    "base_model = keras.models.clone_model(fashion_mnist_cnn_model)\n",
    "base_model.set_weights(fashion_mnist_cnn_model.get_weights())\n",
    "\n",
    "# let's keep all layers except the last two layers (-3 because of dropout)\n",
    "new_model = keras.models.Sequential(base_model.layers[:-3], name='MNIST-CNN-from-pretrained')\n",
    "\n",
    "# set the pre-trained layers to be not trainable\n",
    "for layer_idx, pretrained_layer in enumerate(new_model.layers):\n",
    "    pretrained_layer.trainable = False \n",
    "    \n",
    "# let's add a new dense layer and a new output layer\n",
    "new_model.add(Dense(64, activation='relu', name='fc2'))\n",
    "new_model.add(Dropout(0.4, name='dropout2'))\n",
    "new_model.add(Dense(10, activation=\"softmax\", name='output'))\n",
    "\n",
    "new_model.summary()\n",
    "\n",
    "# compile\n",
    "opt = keras.optimizers.Adam(0.01)\n",
    "new_model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for a few epochs to tune the trainable params\n",
    "history = new_model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's fine-tune the model and allow more training on the pre-trained layers\n",
    "for layer_idx, pretrained_layer in enumerate(new_model.layers):\n",
    "    pretrained_layer.trainable = True \n",
    "\n",
    "# note that we reduce the learning rate for this: we don't want to completely erase the previous weights\n",
    "opt = keras.optimizers.Adam(0.001)\n",
    "\n",
    "new_model.summary()\n",
    "\n",
    "# compile\n",
    "new_model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for a few epochs to tune the trainable params\n",
    "history = new_model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good is our model?\n",
    "loss, acc = new_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can look at some predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 25\n",
    "label_idx = test_y[:num_images].astype(int)\n",
    "labels = np.arange(0, 10)\n",
    "titles = labels[label_idx]\n",
    "plots.plot_images(test_x[:num_images].reshape(-1, 28, 28), dim_x=28, dim_y=28, fig_size=(9,9), titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(test_x[0:2]), test_y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = np.argmax(new_model.predict(test_x[:num_images]), axis=-1)\n",
    "titles = labels[label_idx]\n",
    "plots.plot_images(test_x[:num_images].reshape(-1, 28, 28), dim_x=28, dim_y=28, fig_size=(9,9), titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
