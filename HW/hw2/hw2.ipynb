{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name, email and UFID.\n",
    "Please do not modify instruction cells or any cells with automated tests (marked with `[ASSERTS]`). Note: you can add new cells if you need them, but answers must be in the cells with `YOUR CODE HERE` or \"YOUR ANSWER HERE\" comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d32c3222b2442d52b065e77cd55ac2f",
     "grade": false,
     "grade_id": "homework-preamble",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Homework 2: Regression and Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5658c9a4ed21f362746fdaeb7fb21351",
     "grade": false,
     "grade_id": "preamble-name",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Preamble: Write your Name, Email and UFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cac6c2934a26e1ec9725344dae3cb163",
     "grade": false,
     "grade_id": "name-email-ufid",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homework 2 -- name: Hansika Weerasena, email: hansikam.lokukat@ufl.edu, UFID: 11639514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NAME = 'Hansika Weerasena'\n",
    "EMAIL = 'hansikam.lokukat@ufl.edu'\n",
    "UFID = 11639514\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "print('Homework 2 -- name: {}, email: {}, UFID: {}\\n'.format(NAME, EMAIL, UFID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c41a13a5f6e2fa1b47621d28e926c2cf",
     "grade": true,
     "grade_id": "name-email-ufid-asserts",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check that your name, email, and UFID is filled in.\"\"\"\n",
    "assert NAME != '' and NAME != 'Your name here.' and len(NAME) > 3\n",
    "assert EMAIL != '' and EMAIL != 'Your email here.' and len(EMAIL) > 7\n",
    "assert type(UFID) == int and UFID != 12345678 and UFID >= 10000000 and UFID <= 99999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b4f30c4bbc2f9927b1410eeb1f001b3",
     "grade": false,
     "grade_id": "preamble-academic-integrity",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Academic Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99184dabc791053131230787b9f498b8",
     "grade": false,
     "grade_id": "preamble-academic-integrity-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <span style=\"color:red;\">This is an individual assignment. Academic integrity violations (i.e., cheating, plagiarism) will be reported to SCCR!</span><br/>\n",
    "#### The official CISE policy recommended for such offenses is a course grade of E. Additional sanctions may be imposed by SCCR such as marks on your permanent educational transcripts, dismissal or expulsion.\n",
    "#### Reminder of the Honor Pledge: On all work submitted for credit by Students at the University of Florida, the following pledge is either required or implied: *\"On my honor, I have neither given nor received unauthorized aid in doing this assignment.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d8d2452e1d9f6d547eae6447b7ca369",
     "grade": false,
     "grade_id": "cell-preamble-academic-integrity-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Acknowledgement: Do you acknowledge and understand the academic integrity warning above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89bc9ed2e09cb9069b92dc24a3bc081a",
     "grade": false,
     "grade_id": "academic-integrity",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "academic_integrity_acknowledgement = True\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7d6eb103ab3a60e964c163468d9aa7a",
     "grade": true,
     "grade_id": "academic-integrity-assert",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check that you acknowledge the academic integrity warning, you understand it and have been reminded of the UF Honor Pledge.\"\"\"\n",
    "assert academic_integrity_acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f73a6c8f764fdac6667f0157a544866",
     "grade": false,
     "grade_id": "task1-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# [Task 1] (20 points) Loading and preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd89203347fe0a5164b6775ddd443acb",
     "grade": false,
     "grade_id": "task1-instructb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 1] We will use the Bike Sharing dataset (hourly). A version of this dataset is included in the homework handout archive.\n",
    "### This dataset contains features of users bike sharing/rental on an hourly basis.\n",
    "### The task is to predict how many users are sharing/renting a bike.\n",
    "### In this task you will load the data and preprocess it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40e0c6343e3d6ae8ef5568125e9de64f",
     "grade": false,
     "grade_id": "task1-instructc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### The following cell's code (import statements etc.) is provided for you and you should not need to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "119d3a62a34e7425f288493659994237",
     "grade": false,
     "grade_id": "task1-code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "### Python version: 3.9.6 (default, Nov 10 2023, 13:38:27) \n",
      "[Clang 15.0.0 (clang-1500.1.0.2.5)]\n",
      "### NumPy version: 1.26.3\n",
      "### Scikit-learn version: 1.4.0\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Load packages we need\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Let's check our software versions\n",
    "print('------------')\n",
    "print('### Python version: ' + __import__('sys').version)\n",
    "print('### NumPy version: ' + np.__version__)\n",
    "print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "print('------------')\n",
    "\n",
    "def var_exists(var_name):\n",
    "    return (var_name in globals() or var_name in locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cc6d3b909b447a027649ca1d83883d9",
     "grade": false,
     "grade_id": "seed_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### This is the seed we will use, do not change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d04202483cecc7aa53f8ad98656ef967",
     "grade": false,
     "grade_id": "setting_seed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set the seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "prop_vec = [16, 2, 2] # proportions for train - val - test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d746a78509c270bb1f51eff6a455a1f6",
     "grade": true,
     "grade_id": "seed_checking",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check seed. \"\"\"\n",
    "assert seed == 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b26690ee65de9a82553bc05a151c027e",
     "grade": false,
     "grade_id": "task1-instructd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loading data (set the path correctly so it runs on your machine --- don't submit the data file with your notebook).\n",
    "#### Note: this dataset has missing values (artificially introduced), which you'll need to fill in before you can train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "424a20cc93e7cd774f4c8c7ca4e10b8e",
     "grade": false,
     "grade_id": "task1-loaddata",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Fill in the path to the directory where 'bikesharehour.csv.gz' is located.\n",
    "\"\"\"\n",
    "data_root = 'data/' #put the path here\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f165779998390d2ddff4aea0e0ac8453",
     "grade": true,
     "grade_id": "task1-loaddata-test",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      16320 non-null  float64\n",
      " 1   year        16231 non-null  float64\n",
      " 2   month       16304 non-null  float64\n",
      " 3   hour        16254 non-null  float64\n",
      " 4   holiday     16277 non-null  float64\n",
      " 5   weekday     16282 non-null  float64\n",
      " 6   workingday  16297 non-null  float64\n",
      " 7   weathersit  16324 non-null  float64\n",
      " 8   temp        16242 non-null  float64\n",
      " 9   atemp       16271 non-null  float64\n",
      " 10  hum         16252 non-null  float64\n",
      " 11  windspeed   16281 non-null  float64\n",
      " 12  registered  16244 non-null  float64\n",
      " 13  nsqrtc      16263 non-null  float64\n",
      " 14  count       17379 non-null  int64  \n",
      "dtypes: float64(14), int64(1)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_fp = os.path.join(data_root, 'bikesharehour.csv.gz')\n",
    "assert os.path.exists(dataset_fp), 'Dataset not found ({})!'.format(dataset_fp)\n",
    "df = pd.read_csv(dataset_fp, compression='gzip', header=0, na_values='?')\n",
    "\n",
    "# Check that we loaded the data as expected\n",
    "df_expected_shape = (17379, 15)\n",
    "assert df.shape == df_expected_shape, 'Unexpected shape of df!'\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2658b88a5895c78122a30edae6ae60e1",
     "grade": false,
     "grade_id": "task1a_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 1a] (5 points) Show the first 8 rows of the dataframe df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c184f6d42bf2f1fd7c9d09dcb513c987",
     "grade": false,
     "grade_id": "task1a_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>registered</th>\n",
       "      <th>nsqrtc</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  year  month  hour  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0     1.0   0.0    NaN   0.0      0.0      6.0         0.0         1.0   NaN   \n",
       "1     1.0   0.0    NaN   1.0      0.0      6.0         0.0         1.0   NaN   \n",
       "2     1.0   0.0    1.0   2.0      0.0      6.0         0.0         1.0   0.0   \n",
       "3     1.0   0.0    1.0   3.0      0.0      6.0         0.0         1.0   0.0   \n",
       "4     1.0   0.0    1.0   4.0      0.0      6.0         0.0         1.0   0.0   \n",
       "5     1.0   0.0    1.0   5.0      0.0      6.0         0.0         2.0   0.0   \n",
       "6     1.0   0.0    1.0   6.0      0.0      6.0         0.0         1.0   0.0   \n",
       "7     1.0   0.0    1.0   7.0      0.0      6.0         0.0         1.0   0.0   \n",
       "\n",
       "   atemp  hum  windspeed  registered  nsqrtc  count  \n",
       "0    0.0  0.0        0.0        13.0    -5.0     16  \n",
       "1    0.0  0.0        0.0        32.0    -8.0     40  \n",
       "2    0.0  0.0        0.0        27.0    -7.0     32  \n",
       "3    0.0  0.0        0.0        10.0    -5.0     13  \n",
       "4    0.0  0.0        0.0         1.0     0.0      1  \n",
       "5    0.0  0.0        1.0         1.0     0.0      1  \n",
       "6    0.0  0.0        0.0         0.0     4.0      2  \n",
       "7    NaN  0.0        0.0         2.0    -3.0      3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Put your code here.\n",
    "\"\"\"\n",
    "## what does the data look like?\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df.head(8)\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "207850a57807f6a443236f5a23ef531e",
     "grade": true,
     "grade_id": "task1-features",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['season', 'year', 'month', 'hour', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'registered', 'nsqrtc'] --- target: count\n"
     ]
    }
   ],
   "source": [
    "# grab all the data as a numpy matrix\n",
    "all_xy = df.to_numpy()\n",
    "\n",
    "col_names = [c for c in df.columns]\n",
    "features = col_names[:-1]\n",
    "target = col_names[-1]\n",
    "\n",
    "# what are the features and what is the target?\n",
    "print('features: {} --- target: {}'.format(features, target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c77734990f89e7420bea2fd71508fcc",
     "grade": false,
     "grade_id": "task1b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 1b] (5 points) Answer the following questions by setting variables (hardcoding or computing the answer) from 'all_xy'. (1) If we do supervise learning to predict 'count' based on our features is this classification or regression? (Set the corresponding variable to True.) (2) How many NaNs are there in columns 'holiday','temp', and 'count'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e10a22f5cd4a405b28c06b0d1bafc2a",
     "grade": false,
     "grade_id": "task1b-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here and set the variables appropriately.\n",
    "\"\"\"\n",
    "classification = False\n",
    "regression = True\n",
    "holiday_NaNs = np.sum(np.isnan(all_xy[:,4]))\n",
    "temp_NaNs = np.sum(np.isnan(all_xy[:,8]))\n",
    "count_NaNs = np.sum(np.isnan(all_xy[:,14]))\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc7d99202916a313b25fcfe853eabb82",
     "grade": true,
     "grade_id": "task1b_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check 1b completed. \"\"\"\n",
    "\n",
    "assert var_exists('classification') and var_exists('regression') and classification != regression\n",
    "assert var_exists('holiday_NaNs') and holiday_NaNs >= 0\n",
    "assert var_exists('temp_NaNs') and temp_NaNs >= 0\n",
    "assert var_exists('count_NaNs') and count_NaNs >= 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4c3f1a8772ba51267b07033f0557d23",
     "grade": false,
     "grade_id": "task1c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 1c] (5 points) Let's impute the missing values! Use Scikit-learn's SimpleImputer to replace all NaNs in 'all_xy' with the *most frequent* value in each column. Use copy=True and store the results in 'all_xy_noNaNs' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ed4013643fc31a30fb6b4c395a42fa3",
     "grade": false,
     "grade_id": "task1c_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here (~2-3 lines).\n",
    "\"\"\"\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mode = SimpleImputer(strategy='most_frequent', copy=True)\n",
    "\n",
    "all_xy_noNaNs = imp_mode.fit_transform(all_xy)\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4efd8da58007234bfbad9d825036ade0",
     "grade": true,
     "grade_id": "task1c_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check 1c completed. \"\"\"\n",
    "\n",
    "assert var_exists('all_xy_noNaNs') and all_xy_noNaNs.shape == df_expected_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1024eb6bf3e5eb85b038955feda0cbdc",
     "grade": false,
     "grade_id": "task1d-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 1d] (5 points) Min-max normalize the features (to [0,1] range) using sklearn's MinMaxScaler. Store the results into 'scaled_all_x'. Then split the data into train, val, test according to the proportion in prop_vec using sklearn's train_test split. Store the results into 'train_x', 'train_y', 'test_x', 'test_y', 'val_x', 'val_y'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33549a9e16d2ce1ac32610f23d0c8d16",
     "grade": false,
     "grade_id": "task1d_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here (~5-7 lines).\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# min-max normalize of the features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_all_x = scaler.fit_transform(all_xy_noNaNs[:, :-1])\n",
    "all_y = all_xy_noNaNs[:, -1]  #Target column\n",
    "\n",
    "\n",
    "# First split to separate out the training set\n",
    "train_x, temp_x, train_y, temp_y = train_test_split(scaled_all_x, all_y, test_size=1-(prop_vec[0]/sum(prop_vec)), random_state=42)\n",
    "\n",
    "val_size = prop_vec[1] / (prop_vec[1] + prop_vec[2])\n",
    "\n",
    "# Second split to separate out the validation and test sets\n",
    "val_x, test_x, val_y, test_y = train_test_split(temp_x, temp_y, train_size=val_size, random_state=42)\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f4391b903af2254d5c08592beb7f674",
     "grade": true,
     "grade_id": "task1d_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check split for task 1d. \"\"\"\n",
    "assert var_exists('scaled_all_x')\n",
    "assert var_exists('train_x') and var_exists('train_y') and train_x.shape[0] == train_y.shape[0]\n",
    "assert var_exists('val_x') and var_exists('val_y') and val_x.shape[0] == val_y.shape[0]\n",
    "assert var_exists('test_x') and var_exists('test_y') and test_x.shape[0] == test_y.shape[0]\n",
    "assert train_x.shape == (13903, 14) and val_x.shape == (1738, 14) and test_x.shape == (1738, 14)\n",
    "assert np.amin(train_x) >= 0.0 and np.amax(train_x) <= 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d244ec65844cdeb839f49b48a142b738",
     "grade": false,
     "grade_id": "task2_instructa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 2] (30 points) Evaluating and training linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "468d738a8668ff10566793c58904bae5",
     "grade": false,
     "grade_id": "task2a_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2a] (5 points) Fill in the code to calculate and return the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1d196c4244c95960b2734f67ab68df8",
     "grade": false,
     "grade_id": "task2a_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Fill in your code below (~5-7 lines).\n",
    "\"\"\"\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def r2_mse_mae_eval(model, tr_x, tr_y, v_x, v_y, pref='', verb=True):\n",
    "\n",
    "    \"\"\"Fill in your code below (~1-2 lines).\n",
    "    \"\"\"\n",
    "    # R^2 the coefficient of determination\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    if verb:\n",
    "        print('{}Train R^2: {:.3f}, Val  R^2: {:.3f}'.format(pref, train_r2, val_r2))\n",
    "\n",
    "    train_pred = model.predict(tr_x)\n",
    "    val_pred = model.predict(v_x)\n",
    "\n",
    "    \"\"\"Fill in your code below (~1-2 lines).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    if verb:\n",
    "        print('{}Train MSE: {:.3f}, Val MSE: {:.3f}'.format(pref, train_mse, val_mse))\n",
    "\n",
    "    \"\"\"Fill in your code below (~1-2 lines).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    if verb:\n",
    "        print('{}Train MAE: {:.3f}, Val MAE: {:.3f}'.format(pref, train_mae, val_mae))\n",
    "\n",
    "    return train_r2, val_r2, train_mse, val_mse, train_mae, val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18b3441ddafcf1fd86c8562815958ce4",
     "grade": true,
     "grade_id": "task2a_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check split for task 2a. \"\"\"\n",
    "assert var_exists('r2_mse_mae_eval')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19220fc3ba3d815f8fbcb28390c0ccf7",
     "grade": false,
     "grade_id": "task2b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2b] (5 points) Train a linear regression model using the default (hyper)parameters. Call the resulting trained model 'lrmodel'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dfe0fdc4f5aeae197e64d44281a5e16",
     "grade": false,
     "grade_id": "task2b_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here (~1-2 lines).\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "_ = r2_mse_mae_eval(lrmodel, train_x, train_y, val_x, val_y, pref='[{}] '.format(lrmodel.__class__.__name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4ff682ab212149d93df0732df296ce5",
     "grade": false,
     "grade_id": "task2b-instruct2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2b] How good is that model? (A few sentences is fine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f28a10e885076e373cd3240aae6b68d",
     "grade": true,
     "grade_id": "cell-task2b_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c931713a37b5131c09838b45911da0e8",
     "grade": false,
     "grade_id": "task2c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2c] (5 points) Fill in the code below to setup a grid search. Concatenate the train and val sets into 'search_x' and 'search_y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6adb5fda3e1a8a6253453ee906e3add6",
     "grade": false,
     "grade_id": "task2c_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## some code to do a grid search and automatically train & evaluate the model with the best hyperparams.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def do_grid_search(model, param_grid, x, y):\n",
    "    gs = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error')\n",
    "    gs_res = gs.fit(x, y)\n",
    "    return  gs_res.best_params_\n",
    "\n",
    "\n",
    "def search_train_eval(model, param_grid, tr_x=train_x, tr_y=train_y, v_x=val_x, v_y=val_y):\n",
    "\n",
    "    \"\"\"Put your code here (~2-3 lines). Concatenate the train and val sets into 'search_x' and 'search_y'.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    hyperparams = do_grid_search(model, param_grid, search_x, search_y)\n",
    "    \n",
    "    class_obj = type(model)\n",
    "    m = class_obj(**hyperparams).fit(tr_x, tr_y)\n",
    "    \n",
    "    cn = str(class_obj).split(\"'\")[1]\n",
    "    cn = cn.split('.')[-1]\n",
    "    print('{}({})'.format(cn, hyperparams))\n",
    "\n",
    "    r2_mse_mae_eval(m, tr_x, tr_y, v_x, v_y, pref='\\t')\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48519e6f82d7736ba46225ca36362d92",
     "grade": true,
     "grade_id": "task2c_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 2c. \"\"\"\n",
    "assert var_exists('search_train_eval')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dd2d328fca71fef762e80afcb4c533e",
     "grade": false,
     "grade_id": "task2d_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2d] (10 points) Take a look at the code of search_train_eval() and do_grid_search(). Answer the following questions: \n",
    "### 1. Can you do LAD regression with sklearn? Why or why not? (Justify your answer.) Hint: take a look at the sklearn documentation and the course slides.\n",
    "### 2. Why is the scoring function for the grid search 'neg_mean_squared_error' (as opposed to 'mean_squared_error')? \n",
    "### 3. Why is it okay to do the search over search_x and search_y which are the concatenation of the train and 'validation sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72e30d480e9d39db7c1b99aa78c2dbc9",
     "grade": true,
     "grade_id": "task2d_answer",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "### Hint: take a look at the documentation of scikit-learn and think.\n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64460c67c3a177ebf1ab32de263afbc6",
     "grade": false,
     "grade_id": "task2e_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2e] (5 points) Write the code below to do a grid search on a LassoLars model. Call the resulting model 'lassolars_model'. Be sure to tune the regularization constant and 'fit_intercept'. Make sure training converges and that you set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af01b53b3bacacf8b6212b96621717c2",
     "grade": false,
     "grade_id": "task2e_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here (~2-3 lines).\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4e8cf326726c6095e9cfb210218ede0",
     "grade": true,
     "grade_id": "task2e_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 2e. \"\"\"\n",
    "assert var_exists('lassolars_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad6f73eba9ec23c4ffb8c2f3c9b79b1a",
     "grade": false,
     "grade_id": "task3-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 3] (25 points) Let's train polynomial regression models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fb5dfae82b37f31d9212710d252b6cb",
     "grade": false,
     "grade_id": "task3a-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 3a] (15 points) Use PolynomialFeatures to create a version of the data with all features of degree 3. Follow the provided instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3de785d8bb3ca7ddc296eb8b7968897",
     "grade": false,
     "grade_id": "task3a-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here (~10-15 lines).\n",
    "    1. Use PolynomialFeatures to create a version of the data with all features of degree 3. Make sure to allow interactions (interaction_only=False) and set include_bias=False.\n",
    "    Store the result in 'all_x_pf'. Ensure that you make a copy of the original data and you use the scaled features ('scaled_all_x')!\n",
    "    2. Split the data ('all_x_pf') into train-val-test using proportion from 'prop_vec' and save the result as 'train_{x,y}_pf', 'val_{x,y}_pf', and 'test_{x,y}_pf'.\n",
    "    3. Train three models for comparison. \n",
    "        (a) The first is a ridge regression model 'ridge' on the original scaled data (no polynomial features) where you tuned the hyperparameters.\n",
    "        (b) The second is a linear regression model 'lr_pf' on the polynomial features data.\n",
    "        (c) The third is a regularized \"linear\" model (ridge regression) on the polynomial features data where you tuned the hyperparameters (including regularization constant ensuring alpha >= 1.0).\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a869fcd7d0c1fac1d6f305b5d52afaec",
     "grade": true,
     "grade_id": "task3a-tests",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Checks for task 3a. \"\"\"\n",
    "assert var_exists('all_x_pf') and all_x_pf.shape == (17379, 679)\n",
    "assert var_exists('train_x_pf') and var_exists('train_y_pf') and train_x_pf.shape[0] == train_y_pf.shape[0]\n",
    "assert var_exists('val_x_pf') and var_exists('val_y_pf') and val_x_pf.shape[0] == val_y_pf.shape[0]\n",
    "assert var_exists('test_x_pf') and var_exists('test_y_pf') and test_x_pf.shape[0] == test_y_pf.shape[0]\n",
    "assert train_x_pf.shape[0] == 13903 and val_x_pf.shape[0] == 1738 and test_x_pf.shape == val_x_pf.shape\n",
    "assert train_x_pf.shape[1] == val_x_pf.shape[1]\n",
    "assert np.amin(train_x_pf) >= 0.0 and np.amax(train_x_pf) <= 1.0\n",
    "\n",
    "assert var_exists('ridge_nopf') and var_exists('lr_pf') and var_exists('ridge_pf')\n",
    "assert ridge_nopf.coef_.shape == (14,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5417e88ed3d4f33f7626b96ece3e8ffe",
     "grade": false,
     "grade_id": "task3b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 3b] (5 points) For each of the three models, print the three most important features (coef values and name). You can use 'get_feature_names_out'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6425b4f6904d3ac77fc5e34757315941",
     "grade": false,
     "grade_id": "task3b_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here (~5-7 lines).\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bea6b39d98f12d1f62f27148d85ec62",
     "grade": true,
     "grade_id": "task3b_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" THIS CODE CELL IS INTENTIONALLY LEFT EMPTY.  Remove the 'raise NotImplementedError' line. You should leave this cell empty (it is used for autograding). (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# THIS CODE CELL IS INTENTIONALLY LEFT EMPTY --- DO NOT MODIFY THIS CELL\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c62c7836558e3b4ee481de42b4f56d24",
     "grade": false,
     "grade_id": "task3c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 3c] (5 points) Out of the three models, which would you use and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b344b53283df484008b5ae14a68e8ae4",
     "grade": true,
     "grade_id": "task3c_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "449dab32812541b0bb11bb3e3a649358",
     "grade": false,
     "grade_id": "task4-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 4] (25 points) Trees and Bagging Ensembles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c85c9b2327b4e739bb17ea6c2145c1d",
     "grade": false,
     "grade_id": "task4-instruct2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's do some cleanup and sanity checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a12e338911260c668247d0041d1c859",
     "grade": false,
     "grade_id": "task4-instruct-code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# let's do some cleanup and discard all the polynomial features stuff.\n",
    "if var_exists('all_x_pf'):\n",
    "    del all_x_pf, train_x_pf, train_y_pf, test_x_pf, test_y_pf, val_x_pf, val_y_pf\n",
    "\n",
    "# sanity check shapes\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape, val_x.shape, val_y.shape\n",
    "assert train_x.shape == (13903, 14) and val_x.shape == (1738, 14) and test_x.shape == (1738, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e0011ce50befe631de399acb915a494",
     "grade": false,
     "grade_id": "task4a-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4a] (5 points) Suppose a sklearn decision tree has n nodes. How many total splits does it contain? (Hint: think of it as a CS question not an ML question. Also think about edge cases (e.g., n=0).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "695bdedb230ff2cea44d95bf364ab6a2",
     "grade": false,
     "grade_id": "task4a_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here to answer by implementing the function.\n",
    "\"\"\"\n",
    "def num_dt_splits(nodes): # should return the total number of splits in a decision tree. Must return an integer value.\n",
    "    assert nodes >= 0\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da184360d058a9471fe3344d3dc64b19",
     "grade": true,
     "grade_id": "task4a-tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4a. \"\"\"\n",
    "assert var_exists('num_dt_splits')\n",
    "assert num_dt_splits(0) == 0 and num_dt_splits(1) == 0\n",
    "for i in range(0, 100):\n",
    "    nodes = np.random.randint(0, 1e8)\n",
    "    splits = num_dt_splits(nodes)\n",
    "    assert splits>=0 and splits == int(splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae7566934d1bdc293f09c8fb02e3e788",
     "grade": false,
     "grade_id": "cell-282724082b83b395",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's train a decision tree!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d562ad349530d56c05fe1c5974736c2",
     "grade": false,
     "grade_id": "task4b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4b] (5 points) Train and evaluate two (regression) decision trees with sklearn's DecisionTreeRegressor. The first 'dtmodel' should be trained with default parameters (set the seed). The second 'dtregmodel' should be trained with the default parameters (set the seed) but a max depth of 8. Use r2_mse_mae_eval to print performance of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef9d31fa1e0b4b862b76d2ce94c3668f",
     "grade": false,
     "grade_id": "task4b-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here (~5 lines)\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef804154acc025a0f2dd335fd35fc345",
     "grade": true,
     "grade_id": "task4b-checks",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4b. \"\"\"\n",
    "assert var_exists('dtmodel') and var_exists('dtregmodel') \n",
    "assert dtmodel.tree_.max_depth >= 8 and dtregmodel.tree_.max_depth == 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9de52d5ce39f0ee93b9ea9c7ac11c9f",
     "grade": false,
     "grade_id": "task4c-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4c] (5 points) Is the regularized model overfitted? Is it better than the models trained in Tasks 2 and 3? (A few sentences suffice.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff373393b63e44dd706dd02be10f635c",
     "grade": true,
     "grade_id": "task4c_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60d37ad914f87535f1c9bb16bb9526f7",
     "grade": false,
     "grade_id": "cell-fb9d19cf2516c675",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's explore bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e8dd970d6ffe798592d102494514539",
     "grade": false,
     "grade_id": "task4d_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4d] (5 points) Train two ensemble models using sklearn's BaggingRegressor. Use default parameters but be sure to set the seed and set max_samples=0.5. The first ensemble 'lr_bagging' must use 'LinearRegression' as weak learners, whereas the second 'dtr_bagging' must use 'DecisionTreeRegressor' as weak learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16e5d3a3b91e41285e5e9f093eb1f03c",
     "grade": false,
     "grade_id": "task4d_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here (~3 lines)\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "_ = r2_mse_mae_eval(lr_bagging, train_x, train_y, val_x, val_y, pref='[Linear Regression Bagging] ')\n",
    "print()\n",
    "_ = r2_mse_mae_eval(dtr_bagging, train_x, train_y, val_x, val_y, pref='[DT Regression Bagging aka Random Forest] ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "527ec37234f653709a3f8c57a3febf74",
     "grade": true,
     "grade_id": "task4d_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4d. \"\"\"\n",
    "assert var_exists('lr_bagging') and var_exists('dtr_bagging') \n",
    "assert lr_bagging.random_state == dtr_bagging.random_state and dtr_bagging.random_state == seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1380de7303df21fa79e0942ecf785d86",
     "grade": false,
     "grade_id": "task4e-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4e] (5 points) Answer the following questions: \n",
    "### 1. Is the linear regression bagging ensemble a better model than linear regression (Task 2)? Is this expected? (We are looking for an explanation of why this approach performs the way it does.)\n",
    "### 2. How does the random forest compare to all other models in this and previous task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34e515e74c59752f118ce4e0a5c383c9",
     "grade": true,
     "grade_id": "task4e_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3499cc9afa0dbb2dd6b9244b3eaba066",
     "grade": false,
     "grade_id": "task5_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# [Task 5] \\<*For CAI6108MLE Only*\\> (25 points) Stacking & MoE. For this task you will implement a (kind of) Stacking/MoE approach. \n",
    "# Roughly speaking the approach will be to randomly choose weak learners out of a pool of candidates (determined by the *last* digit of your UFID) and train each one of a randomly selected subset of features. With the weak learners trained, we will train a gating model to learn weights to combine the weak learners' predictions into a single final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "293408be685634ca1bdd7aa55dc4c9dd",
     "grade": false,
     "grade_id": "task5_instruct2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 5] The following code is provided, you should not modify it. But you should *read* it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a99ed5b7f1a30b591f52708cf5b8b8d3",
     "grade": false,
     "grade_id": "task5_provided_code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, LassoLars\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "\"\"\" Returns candidate weak learners based on UFID digit.\n",
    "\"\"\"\n",
    "def weak_learner_candidates(ufid_digit):\n",
    "    if ufid_digit in [1, 3, 6]:\n",
    "        return [SVR(kernel='poly'), Ridge(), DecisionTreeRegressor(max_depth=10)]\n",
    "    elif ufid_digit in [2, 4, 7]:\n",
    "        return [SVR(kernel='poly'), LassoLars(), KNeighborsRegressor(n_neighbors=3)]\n",
    "    else:\n",
    "        assert ufid_digit in [0, 8, 9] \n",
    "        return [DecisionTreeRegressor(max_depth=8), Ridge(), KNeighborsRegressor(n_neighbors=1)]\n",
    "\n",
    "\"\"\" Randomly sample and return a weak learner out of the candidate pool.\n",
    "\"\"\"\n",
    "def random_weak_learner(candidates_fn):\n",
    "    assert candidates_fn is not None\n",
    "\n",
    "    candidates = candidates_fn()\n",
    "    assert len(candidates) == 3\n",
    "    ridx = np.random.randint(0, len(candidates))\n",
    "\n",
    "    return candidates[ridx]\n",
    "\n",
    "\"\"\" Predicts the value(s) on 'x' given the weak_learners and gating function. (Can you figure out how it works??)\n",
    "\"\"\"\n",
    "def predict(weak_learners, gating, x, epsilon=1e-4):\n",
    "    k = len(weak_learners)\n",
    "    \n",
    "    gating_weights = np.ones((x.shape[0], k)) * epsilon\n",
    "    gw = gating.predict_proba(x)\n",
    "    for i, cidx in enumerate(gating.classes_):\n",
    "        gating_weights[:,cidx] = gw[:,i]\n",
    "    gating_weights = gating_weights / np.sum(gating_weights, axis=-1).reshape((-1,1))\n",
    "    \n",
    "    pred_y = np.zeros((x.shape[0],))\n",
    "    for i, tup in enumerate(weak_learners):\n",
    "        weak_learner, sel_features = tup\n",
    "        predi = weak_learner.predict(x[:,sel_features])\n",
    "        pred_y += gating_weights[:,i] * predi\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8f0057245f1024a6d53c389b3486321",
     "grade": false,
     "grade_id": "task5a-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 5a] (10 points) Fill in the code of 'train_ensemble' and 'train_gating' following the provided instructions. Note: instructions do not spell out what every line of code you write should do --- that is for you to figure out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bf9901cd611d84172e788d165f9eaba",
     "grade": false,
     "grade_id": "task5a-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Trains the ensemble of 'num_weak_learners' of randomly chosen weak learners, each selecting a random subset of 'num_sel_features' features.\n",
    "    Returns a list of tuples composed of the trained weak learner ('weak_learner') and the chosen features ('fidx).\n",
    "\"\"\"\n",
    "def train_ensemble(tr_x, tr_y, candidates_fn, num_weak_learners=16, num_sel_features=7):\n",
    "    ret = []\n",
    "    num_features = train_x.shape[1]\n",
    "    for i in range(0, num_weak_learners):\n",
    "\n",
    "        \"\"\"Put your code here (~3-4 lines)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        weak_learner_tup = (weak_learner, fidx)\n",
    "        ret.append(weak_learner_tup)\n",
    "    return ret\n",
    "\n",
    "\n",
    "\"\"\" Trains the gating function (logistic regression) using the provided list of weak learners tuples.\n",
    "    Returns the gating model, errors matrix and best weak learner idx.\n",
    "\"\"\"\n",
    "def train_gating(weak_learners, tr_x, tr_y):\n",
    "    k = len(weak_learners)\n",
    "    errors = np.ones((tr_x.shape[0], k)) * np.inf\n",
    "    \"\"\"Put your code here (~3-4 lines). For each weak learner measure its *absolute errors* on tr_{x,y} (put that in 'errors').\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    bestidx = np.argmin(errors, axis=-1) # compute the weak learning idx with the lowest error\n",
    "    \n",
    "    # train a logistic regression model for the gating\n",
    "    class_weight = {i:1.0 for i in range(0, k)}\n",
    "    gating = LogisticRegression(penalty='l2', C=1.0, random_state=seed, max_iter=10000, class_weight=class_weight, multi_class='multinomial')\n",
    "    gating.fit(tr_x, bestidx)\n",
    "\n",
    "    return gating, errors, bestidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51c93ac8ed11f6fa777471dc8dabdfcd",
     "grade": true,
     "grade_id": "task5a-checks",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 5a. \"\"\"\n",
    "assert var_exists('weak_learner_candidates') and var_exists('random_weak_learner') \n",
    "assert var_exists('train_gating') and var_exists('train_ensemble') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfce67c6e346df2c380433e8ff8b63eb",
     "grade": false,
     "grade_id": "task5b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 5b] (10 points) Fill in the provided code. Use the functions you previously implemented to train the ensemble and the gating models and make predictions on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a92c9bec3d92d5b7d18a3bc037d9534",
     "grade": false,
     "grade_id": "task5b-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "\n",
    "\"\"\"Put your code here (~3-4 lines). \n",
    "    1. Split the training data into s1_{x,y} and s2_{x,y} such that 70% ends up in s1 (and 30% in s2).\n",
    "    2. train the ensemble on s1_{x,y} [do not forget to use the *last* digit of your UFID].\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# train the gating on s2_{x,y}\n",
    "gating, errors, bestidx = train_gating(wls, s2_x, s2_y)\n",
    "# use the predict function to make predictions on the validation data\n",
    "pred_y = predict(wls, gating, val_x)\n",
    "\n",
    "\"\"\"Put your code here (~3-4 lines). \n",
    "    compute the R^2, MSE, MAE on the validation data (using 'pred_y') and store the result as 'val_r2', 'val_mse', 'val_mae'\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "et = time.time()\n",
    "elapsed = et - st\n",
    "print('[Val] R^2: {:.3f}, MSE: {:.1f}, MAE: {:.1f} [Elapsed: {:.1f} seconds]'.format(val_r2, val_mse, val_mae, elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "797a5b0af1bcbb19f897190a86dc79b9",
     "grade": true,
     "grade_id": "task5b_tests",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 5b. \"\"\"\n",
    "\n",
    "assert var_exists('gating')\n",
    "assert elapsed < 300.0\n",
    "assert np.abs(val_r2 - 0.88) <= 0.12 and np.abs(val_mae - 30) <= 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18b847192d58dc3d9c4c4f1e993e0407",
     "grade": false,
     "grade_id": "task5c-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 5c] (5 points) Now observe that 'num_weak_learners' and 'num_sel_features' in train_ensemble can be considered hyperparameters. Write some code to tune them through a simple grid search and then print the best value for them and the performance of the resulting ensemble model. (For this question best means the one with lowest val R^2.) Is it better than previous models in this homework?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0338b34208be0df1b92b0ae90fbae45a",
     "grade": false,
     "grade_id": "task5c-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here. Call the resulting best hyperparameters 'best_num_weak_learners' and 'best_num_sel_features'\n",
    "    Store the performance R^2, MSE, MAE as 'val_r2', 'val_mse', 'val_mae'\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print('[Val] R^2: {:.3f}, MSE: {:.1f}, MAE: {:.1f} [Best hyperparams: {}, {}]'.format(val_r2, val_mse, val_mae, best_num_weak_learners, best_num_sel_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2ee25aea7b3cdffb0705fd51f663f74",
     "grade": true,
     "grade_id": "task5c-checks",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 5c. \"\"\"\n",
    "\n",
    "assert var_exists('best_num_weak_learners') and var_exists('best_num_sel_features')\n",
    "assert np.abs(val_r2 - 0.92) <= 0.08 and np.abs(val_mae - 24) <= 24\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
